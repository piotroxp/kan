# Training Status - Active

## âœ… Training Started Successfully

**Configuration:**
- Batch Size: 16
- Learning Rate: 1e-4  
- Epochs: 50
- Current: Epoch 1/50

**Status:** Running in background

## Monitor Training

### Check progress:
```bash
tail -f build/training.log
```

### Check if still running:
```bash
ps aux | grep "./train" | grep -v grep
```

### View latest output:
```bash
tail -50 build/training.log
```

## Training Output Format

Each epoch will show:
```
Epoch X/50
  Loss: <total>
    Audio: <value>
    Quantum: <value>
    Classification: <value>
    L2: <value>
    Normalization: <value>
  Samples: <count>
```

Every 5 epochs, validation metrics will be computed.

## Checkpoints

Best model checkpoints are saved to:
- `checkpoints/best_model.ckpt`

## Performance

- **CPU Training**: Currently using CPU (GPU will auto-enable when detected)
- **Throughput**: Depends on system, monitor with `top` or `htop`
- **Memory**: Batch size 16 is optimal for current setup

---

*Training is running! Monitor with `tail -f build/training.log`*



